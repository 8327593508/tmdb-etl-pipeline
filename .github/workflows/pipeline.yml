name: Daily TMDB ETL

on:
  schedule:
    - cron: "0 4 * * *"
  workflow_dispatch:

jobs:
  run-etl:
    runs-on: ubuntu-latest

    steps:

      # -----------------------------
      # 1. Checkout repository
      # -----------------------------
      - name: Checkout repo
        uses: actions/checkout@v4

      # -----------------------------
      # 2. Create .env file
      # -----------------------------
      - name: Create .env from secrets
        run: |
          cat > .env <<EOF
          TMDB_API_KEY=${{ secrets.TMDB_API_KEY }}
          PG_USER=${{ secrets.PG_USER }}
          PG_PASSWORD=${{ secrets.PG_PASSWORD }}
          PG_DB=${{ secrets.PG_DB }}
          PG_PORT=5432
          PG_HOST=postgres
          MAX_PAGES=${{ secrets.MAX_PAGES }}
          SCHEDULE=0
          EOF

      # -----------------------------
      # 3. Start Postgres only
      # -----------------------------
      - name: Start Postgres
        run: docker compose -f docker-compose.ci.yml up -d postgres

      # -----------------------------
      # 4. Run ETL App (one-time)
      # -----------------------------
      - name: Run ETL
        env:
          GITHUB_ACTIONS: "true"
        run: docker compose -f docker-compose.ci.yml run --rm app

      # -----------------------------
      # 5. Export CSVs from Postgres
      # -----------------------------
      - name: Export CSV files
        run: |
          echo "Cleaning old data folder"
          rm -rf data
          mkdir -p data

          echo "Finding Postgres container..."
          PG_CONTAINER=$(docker ps --filter "name=tmdb_pipeline_postgres" --format "{{.ID}}")
          echo "Postgres container ID = $PG_CONTAINER"

          echo "Running COPY commands..."
          docker exec "$PG_CONTAINER" psql -U ${{ secrets.PG_USER }} -d ${{ secrets.PG_DB }} -c "\COPY popular_movies TO '/tmp/popular_movies.csv' CSV HEADER;"
          docker exec "$PG_CONTAINER" psql -U ${{ secrets.PG_USER }} -d ${{ secrets.PG_DB }} -c "\COPY movie_details TO '/tmp/movie_details.csv' CSV HEADER;"
          docker exec "$PG_CONTAINER" psql -U ${{ secrets.PG_USER }} -d ${{ secrets.PG_DB }} -c "\COPY movie_credits TO '/tmp/movie_credits.csv' CSV HEADER;"

          echo "Copying CSV files to repo..."
          docker cp "$PG_CONTAINER":/tmp/popular_movies.csv data/popular_movies.csv
          docker cp "$PG_CONTAINER":/tmp/movie_details.csv data/movie_details.csv
          docker cp "$PG_CONTAINER":/tmp/movie_credits.csv data/movie_credits.csv

          echo "Final CSV file list:"
          ls -lh data/

      # -----------------------------
      # 6. Commit CSVs to GitHub
      # -----------------------------
      - name: Commit updated CSVs
        uses: stefanzweifel/git-auto-commit-action@v4
        with:
          commit_message: "Update TMDB CSV files"
          file_pattern: tmdb-etl-pipeline/data/popular_movies.csv
          branch: main

      # -----------------------------
      # 7. Cleanup
      # -----------------------------
      - name: Cleanup containers
        if: always()
        run: docker compose -f docker-compose.ci.yml down --volumes
