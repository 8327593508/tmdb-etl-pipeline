name: Daily TMDB Multi-File ETL

on:
  workflow_dispatch:
  schedule:
    - cron: "0 6 * * *"

jobs:
  etl:
    runs-on: ubuntu-latest

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Create .env from secrets
        run: |
          cat > .env <<EOF
          TMDB_API_KEY=${{ secrets.TMDB_API_KEY }}
          PG_USER=${{ secrets.PG_USER }}
          PG_PASSWORD=${{ secrets.PG_PASSWORD }}
          PG_DB=${{ secrets.PG_DB }}
          PG_HOST=postgres
          PG_PORT=5432
          MAX_PAGES=${{ secrets.MAX_PAGES }}
          SCHEDULE=0
          EOF

      - name: Build Docker images
        run: docker compose -f docker-compose.ci.yml build --no-cache

      - name: Start Postgres only
        run: docker compose -f docker-compose.ci.yml up -d postgres

      - name: Wait for Postgres to be ready
        run: |
          echo "Waiting for Postgres..."
          for i in {1..30}; do
            if docker logs tmdb_pipeline_postgres 2>&1 | grep -q "database system is ready"; then
              echo "Postgres is ready!"
              exit 0
            fi
            sleep 2
          done
          echo "Postgres did NOT start"
          exit 1

      - name: Run ETL container
        env:
          GITHUB_ACTIONS: "true"
        run: docker compose -f docker-compose.ci.yml run --rm app

      - name: Export CSV files
        env:
          PG_USER: ${{ secrets.PG_USER }}
          PG_DB: ${{ secrets.PG_DB }}
        run: |
          REPO_DIR="tmdb-etl-pipeline"

          PG_CONTAINER=$(docker ps --filter "name=tmdb_pipeline_postgres" --format "{{.ID}}")
          echo "Postgres container = $PG_CONTAINER"

          # Ensure repo data folder exists
          mkdir -p "$REPO_DIR/data"

          echo "Exporting CSV from inside container..."
          docker exec "$PG_CONTAINER" psql -U "$PG_USER" -d "$PG_DB" -c "\COPY popular_movies TO '/tmp/popular_movies.csv' CSV HEADER;"
          docker exec "$PG_CONTAINER" psql -U "$PG_USER" -d "$PG_DB" -c "\COPY movie_details TO '/tmp/movie_details.csv' CSV HEADER;"
          docker exec "$PG_CONTAINER" psql -U "$PG_USER" -d "$PG_DB" -c "\COPY movie_credits TO '/tmp/movie_credits.csv' CSV HEADER;"

          echo "Copying CSV files to repo..."
          docker cp "$PG_CONTAINER":/tmp/popular_movies.csv "$REPO_DIR/data/popular_movies.csv"
          docker cp "$PG_CONTAINER":/tmp/movie_details.csv "$REPO_DIR/data/movie_details.csv"
          docker cp "$PG_CONTAINER":/tmp/movie_credits.csv "$REPO_DIR/data/movie_credits.csv"

          echo "Files in repo data folder:"
          ls -lh "$REPO_DIR/data"

      - name: Commit CSV updates
        uses: stefanzweifel/git-auto-commit-action@v4
        with:
          file_pattern: "tmdb-etl-pipeline/data/*.csv"
          commit_message: "Update TMDB CSV files"
          branch: main

      - name: Cleanup
        if: always()
        run: docker compose -f docker-compose.ci.yml down -v
